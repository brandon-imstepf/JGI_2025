{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525380b4",
   "metadata": {},
   "source": [
    "# Hyperparameter Sweep Error Analysis\n",
    "\n",
    "This notebook scans `logs/hparam_sweep/<dataset_subset>/` for training logs, extracts the best error metrics, and visualizes error-focused summaries per dataset/subset. Run it after each sweep to see how the new jobs performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52ae9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb19239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_sorted_floats_only'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_sorted_floats_plus_onehot_no_middle'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_sorted_full'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_sorted_intersect_floats_only'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_sorted_intersect_floats_plus_onehot_no_middle'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_sorted_onehot_only'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_floats_only'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_floats_plus_onehot_no_middle'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_full'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_intersect_floats_only'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_intersect_floats_plus_onehot_no_middle'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_intersect_full'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_intersect_onehot_only'),\n",
       " PosixPath('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf/logs/hparam_sweep/ncbi_training_onehot_only')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ROOT = Path('/clusterfs/jgi/scratch/gentech/genome_analysis/brandonimstepf')\n",
    "LOG_ROOT = PROJECT_ROOT / 'logs' / 'hparam_sweep'\n",
    "KNOWN_SUBSETS = ['full','floats_only','onehot_only','floats_plus_onehot_no_middle']\n",
    "LOG_COMBOS = sorted(p for p in LOG_ROOT.iterdir() if p.is_dir())\n",
    "LOG_COMBOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "caef12b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>dataset</th>\n",
       "      <th>subset</th>\n",
       "      <th>parameter</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>parameter_value</th>\n",
       "      <th>status</th>\n",
       "      <th>err</th>\n",
       "      <th>wer</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>ctf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ncbi_sorted_floats_only</td>\n",
       "      <td>ncbi_sorted</td>\n",
       "      <td>floats_only</td>\n",
       "      <td>activation_msig_high</td>\n",
       "      <td>msig</td>\n",
       "      <td>0.024</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncbi_sorted_floats_only</td>\n",
       "      <td>ncbi_sorted</td>\n",
       "      <td>floats_only</td>\n",
       "      <td>activation_msig_low</td>\n",
       "      <td>msig</td>\n",
       "      <td>0.016</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ncbi_sorted_floats_only</td>\n",
       "      <td>ncbi_sorted</td>\n",
       "      <td>floats_only</td>\n",
       "      <td>activation_rslog_high</td>\n",
       "      <td>rslog</td>\n",
       "      <td>0.024</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ncbi_sorted_floats_only</td>\n",
       "      <td>ncbi_sorted</td>\n",
       "      <td>floats_only</td>\n",
       "      <td>activation_rslog_low</td>\n",
       "      <td>rslog</td>\n",
       "      <td>0.016</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ncbi_sorted_floats_only</td>\n",
       "      <td>ncbi_sorted</td>\n",
       "      <td>floats_only</td>\n",
       "      <td>activation_sig_high</td>\n",
       "      <td>sig</td>\n",
       "      <td>0.72</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     combo      dataset       subset              parameter  \\\n",
       "0  ncbi_sorted_floats_only  ncbi_sorted  floats_only   activation_msig_high   \n",
       "1  ncbi_sorted_floats_only  ncbi_sorted  floats_only    activation_msig_low   \n",
       "2  ncbi_sorted_floats_only  ncbi_sorted  floats_only  activation_rslog_high   \n",
       "3  ncbi_sorted_floats_only  ncbi_sorted  floats_only   activation_rslog_low   \n",
       "4  ncbi_sorted_floats_only  ncbi_sorted  floats_only    activation_sig_high   \n",
       "\n",
       "  parameter_name parameter_value status  err  wer  fpr  fnr  ctf  \n",
       "0           msig           0.024   FAIL  NaN  NaN  NaN  NaN  NaN  \n",
       "1           msig           0.016   FAIL  NaN  NaN  NaN  NaN  NaN  \n",
       "2          rslog           0.024   FAIL  NaN  NaN  NaN  NaN  NaN  \n",
       "3          rslog           0.016   FAIL  NaN  NaN  NaN  NaN  NaN  \n",
       "4            sig            0.72   FAIL  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BEST_PATTERN = re.compile(r\"Best:\\s+ERR=\\s+(?P<err>[0-9.]+)\\s+WER=\\s+(?P<wer>[0-9.]+)\\s+FPR=\\s+(?P<fpr>[0-9.]+)\\s+FNR=\\s+(?P<fnr>[0-9.]+)\\s+CTF=\\s+(?P<ctf>[0-9.\\-]+)\")\n",
    "CMD_PATTERN = re.compile(r\"([A-Za-z_]+)=([0-9.eE+-]+)\")\n",
    "\n",
    "PREFIXES = (\"general_\",\"mse_\",\"legacy_\",\"triage_\",\"wbce_\",\"tversky_\")\n",
    "SUFFIX_MAP = {\"high\":\"*1.2\",\"low\":\"*0.8\"}\n",
    "\n",
    "def split_combo(name: str) -> Tuple[str,str]:\n",
    "    for subset in KNOWN_SUBSETS:\n",
    "        suffix = f\"_{subset}\"\n",
    "        if name.endswith(suffix):\n",
    "            dataset = name[: -len(suffix)]\n",
    "            if dataset.endswith('_'):\n",
    "                dataset = dataset[:-1]\n",
    "            return dataset, subset\n",
    "    return name, 'unknown'\n",
    "\n",
    "\n",
    "def parse_command(line: str) -> Dict[str,str]:\n",
    "    return {k:v for k,v in CMD_PATTERN.findall(line)}\n",
    "\n",
    "\n",
    "def extract_param_value(label: str, cmd_map: Dict[str,str]) -> Tuple[str,str]:\n",
    "    parts = label.split('_')\n",
    "    prefix = parts[0]\n",
    "    suffix = parts[-1]\n",
    "    core = '_'.join(parts[1:-1]) if len(parts) > 2 else (parts[1] if len(parts) >1 else parts[0])\n",
    "    if prefix == 'triage' or core == 'triage':\n",
    "        pval = cmd_map.get('ptriage')\n",
    "        nval = cmd_map.get('ntriage')\n",
    "        val = f\"ptriage={pval},ntriage={nval}\" if pval and nval else suffix\n",
    "        return 'triage', val\n",
    "    # remove prefix indicators from core\n",
    "    for pre in ('general_','mse_','legacy_','wbce_','tversky_'):\n",
    "        if core.startswith(pre):\n",
    "            core = core[len(pre):]\n",
    "    core = core or parts[1] if len(parts)>1 else parts[0]\n",
    "    actual = cmd_map.get(core)\n",
    "    if actual:\n",
    "        return core, actual\n",
    "    # fallback to suffix mapping\n",
    "    return core, SUFFIX_MAP.get(suffix, suffix)\n",
    "\n",
    "\n",
    "def parse_log(path: Path) -> Dict:\n",
    "    text = path.read_text(errors='replace')\n",
    "    lines = text.splitlines()\n",
    "    cmd_map = parse_command(lines[0]) if lines else {}\n",
    "    match = BEST_PATTERN.search(text)\n",
    "    status = 'SUCCESS' if match else 'FAIL'\n",
    "    metrics = {k: float(v) for k, v in match.groupdict().items()} if match else {}\n",
    "    dataset, subset = split_combo(path.parent.name)\n",
    "    param_name, param_value = extract_param_value(path.stem, cmd_map)\n",
    "    return {\n",
    "        'combo': path.parent.name,\n",
    "        'dataset': dataset,\n",
    "        'subset': subset,\n",
    "        'parameter': path.stem,\n",
    "        'parameter_name': param_name,\n",
    "        'parameter_value': param_value,\n",
    "        'status': status,\n",
    "        **metrics,\n",
    "    }\n",
    "\n",
    "\n",
    "def collect_records(dirs: Iterable[Path]) -> pd.DataFrame:\n",
    "    records: List[Dict] = []\n",
    "    for combo_dir in dirs:\n",
    "        for log_path in combo_dir.glob('*.log'):\n",
    "            records.append(parse_log(log_path))\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "df = collect_records(LOG_COMBOS)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "33e4bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print('No logs found yet.')\n",
    "else:\n",
    "    subset_summary = (\n",
    "        df.groupby(['dataset','subset','status'])\n",
    "          .size()\n",
    "          .unstack(fill_value=0)\n",
    "          .assign(total=lambda x: x.sum(axis=1))\n",
    "          .sort_values('total', ascending=False)\n",
    "    )\n",
    "    subset_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba6afdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total successful dataset/subset combos: 2\n"
     ]
    }
   ],
   "source": [
    "# List dataset/subset combos with at least one successful run\n",
    "if df.empty:\n",
    "    print('No logs available.')\n",
    "else:\n",
    "    success_sets = (\n",
    "        df[df['status']=='SUCCESS']\n",
    "        .groupby(['dataset','subset'])\n",
    "        .size()\n",
    "        .reset_index(name='success_count')\n",
    "        .sort_values('success_count', ascending=False)\n",
    "    )\n",
    "    if success_sets.empty:\n",
    "        print('No successful runs yet.')\n",
    "    else:\n",
    "        print(f\"Total successful dataset/subset combos: {len(success_sets)}\")\n",
    "        success_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "29c5b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print('No data to summarize.')\n",
    "else:\n",
    "    success_df = df[df['status']=='SUCCESS']\n",
    "    if success_df.empty:\n",
    "        print('No successful runs yet.')\n",
    "    else:\n",
    "        err_summary = (\n",
    "            success_df.groupby(['dataset','subset'])['err']\n",
    "                      .agg(['min','median','max','count'])\n",
    "                      .sort_values('median')\n",
    "        )\n",
    "        err_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa21cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print('No logs found to export.')\n",
    "else:\n",
    "    success_df = df[df['status']=='SUCCESS'].copy()\n",
    "    if success_df.empty:\n",
    "        print('No successful runs to export.')\n",
    "    else:\n",
    "        success_df[['parameter_base','param_suffix']] = success_df['parameter'].str.rsplit('_', n=1, expand=True)\n",
    "        success_df['parameter_name'] = success_df['parameter_base'].str.replace('^general_|^mse_|^legacy_|^triage_', '', regex=True)\n",
    "        success_df['parameter_value'] = success_df['param_suffix'].map({'high':'*1.2','low':'*0.8'}).fillna(success_df['param_suffix'])\n",
    "        export_df = (success_df.groupby(['dataset','subset','parameter_name','parameter_value'])['err']\n",
    "                     .min().reset_index())\n",
    "        export_path = PROJECT_ROOT / 'logs' / 'hparam_sweep' / 'hparam_error_summary.csv'\n",
    "        export_df.to_csv(export_path, index=False)\n",
    "        export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3ed2b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the top-performing parameter for each subset\n",
    "if df.empty:\n",
    "    print('No data to highlight.')\n",
    "else:\n",
    "    success_df = df[df['status']=='SUCCESS']\n",
    "    if success_df.empty:\n",
    "        print('No successful runs to highlight.')\n",
    "    else:\n",
    "        top_params = (\n",
    "            success_df.sort_values('err')\n",
    "            .groupby(['dataset','subset'])\n",
    "            .first()[['parameter','err']]\n",
    "        )\n",
    "        top_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6c6d53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print('No logs found to export.')\n",
    "else:\n",
    "    success_df = df[df['status']=='SUCCESS']\n",
    "    if success_df.empty:\n",
    "        print('No successful runs to export.')\n",
    "    else:\n",
    "        export_df = success_df.groupby(['dataset','subset','parameter'])['err'].min().reset_index()\n",
    "        export_path = PROJECT_ROOT / 'logs' / 'hparam_sweep' / 'hparam_error_summary.csv'\n",
    "        export_df.to_csv(export_path, index=False)\n",
    "        export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a0aa363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print('No logs yet.')\n",
    "else:\n",
    "    success_df = df[df['status']=='SUCCESS'].copy()\n",
    "    if success_df.empty:\n",
    "        print('No successful runs yet.')\n",
    "    else:\n",
    "        success_df[['parameter_base','param_suffix']] = success_df['parameter'].str.rsplit('_', n=1, expand=True)\n",
    "        success_df['parameter_name'] = success_df['parameter_base'].str.replace('^general_|^mse_|^legacy_|^triage_','',regex=True)\n",
    "        success_df['parameter_value'] = success_df['param_suffix'].map({'high':'*1.2','low':'*0.8'}).fillna(success_df['param_suffix'])\n",
    "        best_table = (success_df.sort_values('err')\n",
    "                      .groupby(['dataset','subset','parameter_name','parameter_value'])[['err','wer','fpr','fnr','ctf']]\n",
    "                      .first()\n",
    "                      .reset_index())\n",
    "        best_table.head(50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
